# import torch
# from ptflops import get_model_complexity_info
# from model import NetworkBasic
# import slayerSNN as snn


# def count_flops():
#     # åŠ è½½ SNN é…ç½®
#     netParams = snn.params('./nMnist/network.yaml')

#     # åˆ›å»ºæ¨¡å‹å¹¶è®¾ç½®ä¸º evaluation æ¨¡å¼
#     model = NetworkBasic(netParams)
#     model.eval()

#     # input_shape: è¿™é‡Œçš„å°ºå¯¸æ˜¯ä½ æ¨¡å‹ forward çš„è¾“å…¥å°ºå¯¸ï¼Œä¸åŒ…æ‹¬ batch size
#     input_shape = (2, 17, 17, 350)  # å¯¹åº” [C, H, W, T]
    
#     # ptflops åªæ”¯æŒ NCHWï¼Œå˜æ¢æˆ [C, T, H, W] => reshape ä¸º [C*T, H, W]
#     c, h, w, t = input_shape
#     flops_shape = (c * t, h, w)  # æ³¨æ„ä¸è¦åŒ…å« batch dim

#     # åŒ…è£…ä¸€ä¸‹æ¨¡å‹ forwardï¼Œè®©å®ƒæ¥å— 4D è¾“å…¥
#     class Wrapper(torch.nn.Module):
#         def __init__(self, model):
#             super().__init__()
#             self.model = model

#         def forward(self, x):
#             # å°† 4D x (C*T, H, W) è¿˜åŸä¸ºåŸå§‹ 5D spike tensor: [B, C, H, W, T]
#             B, CT, H, W = x.shape
#             x = x.view(B, c, t, H, W).permute(0, 1, 3, 4, 2)  # [B, C, H, W, T]
#             return self.model(x)

#     wrapped_model = Wrapper(model)

#     with torch.cuda.device(0):
#         macs, params = get_model_complexity_info(wrapped_model, (c*t, h, w), as_strings=True, print_per_layer_stat=True)
#         print(f"FLOPs: {macs}")
#         print(f"Params: {params}")


# if __name__ == '__main__':
#     count_flops()



"""
æœ¬è„šæœ¬åªä¼°ç®—äº†ä¸¤å±‚å·ç§¯ï¼Œä¸åŒ…å«å…¶ä»–å¦‚ PSP/spike å¤„ç†ï¼Œå› ä¸ºå®ƒä»¬æ˜¯äº‹ä»¶ç¥ç»ç½‘ç»œç‰¹æœ‰æ“ä½œï¼Œä¸é€‚ç”¨æ ‡å‡† FLOPs æ¨¡å‹ã€‚
spike/spikePSP ç­‰ç¥ç»åŠ¨åŠ›å­¦è¿‡ç¨‹ä¸è®¡å…¥ FLOPsï¼ˆé€šå¸¸ä¹Ÿæ— æ³•å‡†ç¡®å»ºæ¨¡ï¼‰
"""



# def estimate_flops_conv3d(Cin, Cout, K, H, W, T):
#     """
#     ä¼°ç®— 3D å·ç§¯ FLOPsï¼š
#     æ¯ä¸ªè¾“å‡ºä½ç½®ï¼šCout Ã— (Cin Ã— K Ã— K) æ¬¡ä¹˜æ³• + ç›¸åŒæ•°é‡åŠ æ³• â‰ˆ 2 Ã— Cout Ã— Cin Ã— K Ã— K
#     æ€» FLOPs = 2 Ã— Cout Ã— Cin Ã— KÂ² Ã— H Ã— W Ã— T
#     """
#     return 2 * Cout * Cin * (K ** 2) * H * W * T


# def estimate_params_conv(Cin, Cout, K):
#     """ä¼°ç®—æ™®é€š 2D å·ç§¯å±‚çš„å‚æ•°æ•°é‡"""
#     return Cout * Cin * K * K


# if __name__ == "__main__":
#     # è¾“å…¥å¼ é‡å°ºå¯¸ [B, C=2, H=17, W=17, T=350]
#     Cin1, Cout1, K1 = 2, 8, 5  # conv1
#     Cin2, Cout2, K2 = 8, 1, 2  # convTranspose

#     # å±‚1ï¼šåŸå§‹åˆ†è¾¨ç‡
#     H1, W1, T = 17, 17, 350

#     # å±‚2ï¼šç»è¿‡ä¸Šé‡‡æ ·åçš„åˆ†è¾¨ç‡
#     H2, W2 = H1 * 2, W1 * 2

#     # è®¡ç®— FLOPs
#     flops_conv1 = estimate_flops_conv3d(Cin1, Cout1, K1, H1, W1, T)
#     flops_upconv1 = estimate_flops_conv3d(Cin2, Cout2, K2, H2, W2, T)
#     total_flops = flops_conv1 + flops_upconv1

#     # è®¡ç®—å‚æ•°é‡
#     params_conv1 = estimate_params_conv(Cin1, Cout1, K1)
#     params_upconv1 = estimate_params_conv(Cin2, Cout2, K2)
#     total_params = params_conv1 + params_upconv1

#     # è¾“å‡ºç»“æœ
#     print(f"[conv1] FLOPs:        {flops_conv1 / 1e6:.2f} MFLOPs, Params: {params_conv1}")
#     print(f"[upconv1] FLOPs:      {flops_upconv1 / 1e6:.2f} MFLOPs, Params: {params_upconv1}")
#     print(f"Total FLOPs:          {total_flops / 1e6:.2f} MFLOPs")
#     print(f"Total Trainable Params: {total_params} ({total_params / 1e6:.3f} M)")



"""
è¿™æ˜¯æ‰‹åŠ¨è®¡ç®—çš„ï¼Œè‡ªåŠ¨çš„è¯†åˆ«ä¸å‡ºSlayer çš„å·ç§¯å±‚
"""

import torch
from model import NetworkBasic
import slayerSNN as snn

# ğŸ”§ å¡«å†™å®é™…è¾“å…¥å°ºå¯¸
C_in, H_in, W_in, T = 2, 34, 34, 350  # åŒææ€§é€šé“ï¼Œ180x240ï¼Œ1500æ—¶é—´æ­¥
input_shape = (C_in, H_in, W_in, T)

# âœ… åŠ è½½ Slayer å‚æ•°
netParams = snn.params('./nMnist/network.yaml')
model = NetworkBasic(netParams).cuda()

T = 350

def count_conv_flops(H, W, Cin, Cout, K, stride=1, upsample=False):
    if upsample:
        H, W = H * stride, W * stride
    flops = 2 * H * W * Cin * K * K * Cout * T  # âœ… æ³¨æ„ä¹˜ T
    return flops, H, W

# ğŸ‘‰ é€å±‚ç»Ÿè®¡ï¼ˆä»¥ä¸‹ä»…ä¸¾ä¾‹ï¼Œéœ€æŒ‰ä½ æ¨¡å‹å®é™…ç»“æ„å¡«å†™ï¼‰
total_flops = 0
total_params = 0

# conv1: in=2, out=8, k=5, stride=1, no upsampling
flops, H1, W1 = count_conv_flops(H_in, W_in, 2, 8, K=5)
params = 2 * 8 * 5 * 5  # Cin * Cout * Kh * Kw
print(f"[conv1] FLOPs: {flops/1e9:.2f} GFLOPs, Params: {params}")
total_flops += flops
total_params += params

# conv2: in=8, out=8, k=3, stride=1
flops, H2, W2 = count_conv_flops(H1, W1, 8, 8, K=3)
params = 8 * 8 * 3 * 3
print(f"[conv2] FLOPs: {flops/1e9:.2f} GFLOPs, Params: {params}")
total_flops += flops
total_params += params

# upconv1: TransposedConv, in=8, out=2, k=2, stride=2
flops, H3, W3 = count_conv_flops(H2, W2, 8, 2, K=2, stride=2, upsample=True)
params = 8 * 2 * 2 * 2
print(f"[upconv1] FLOPs: {flops/1e9:.2f} GFLOPs, Params: {params}")
total_flops += flops
total_params += params

# âœ… è¾“å‡ºæ€»è®¡
print(f"âœ… Total FLOPs: {total_flops/1e9:.2f} GFLOPs")
print(f"âœ… Total Trainable Params: {total_params} ({total_params/1e6:.3f} M)")




