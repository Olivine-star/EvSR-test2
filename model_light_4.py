import torch
import slayerSNN as snn
from utils.utils import getNeuronConfig
import numpy as np


class NetworkBasic(torch.nn.Module):
    """
    è¿™ä¸ªæ¨¡å‹å°±ç”±trainNmnistä¼ å…¥ä¸¤ä¸ªå‚æ•°ï¼šnetParamså’Œä¼ å…¥spikeInput
    netParams = snn.params('network.yaml'),è°ƒç”¨æ¨¡å‹ç±»ï¼Œåˆ›å»ºç½‘ç»œå¯¹è±¡,m = NetworkBasic(netParams)
    output = m(eventLr)ï¼ŒeventLrå°±æ˜¯ä¼ å…¥forwardçš„å‚æ•°spikeInput
    """
    #
    def __init__(self, netParams,
                 theta=[30, 100],
                 tauSr=[1, 4],
                 tauRef=[1, 4],
                 scaleRef=[1, 1],
                 tauRho=[1, 10],
                 scaleRho=[10, 100]):
        super(NetworkBasic, self).__init__()

        """
        æ¯ä¸€å±‚ç¥ç»å…ƒçš„è¡Œä¸ºç”± getNeuronConfig(...) å‡½æ•°é…ç½®ï¼Œå¦‚é˜ˆå€¼ã€è¡°å‡æ—¶é—´ç­‰ï¼Œæ˜¯ SNN ç‰¹æœ‰çš„ã€‚
        è¿™æ˜¯ä¸ºäº†ç»™æ¯ä¸€å±‚è®¾ç½®ä¸åŒçš„ç¥ç»å…ƒè¡Œä¸ºå‚æ•°ï¼Œå› ä¸ºåœ¨ SNN ä¸­ï¼šç¥ç»å…ƒä¸å†æ˜¯æ™®é€šçš„ ReLU æ¿€æ´»å•å…ƒï¼Œè€Œæ˜¯å…·æœ‰ç”Ÿç‰©å¯å‘ç‰¹æ€§çš„è„‰å†²ç¥ç»å…ƒï¼›

        å‚æ•°å¦‚ thetaï¼ˆå‘æ”¾é˜ˆå€¼ï¼‰ã€tauSrï¼ˆçªè§¦å“åº”æ—¶é—´å¸¸æ•°ï¼‰ã€tauRefï¼ˆä¸åº”æœŸæ—¶é—´ï¼‰ã€scaleRhoï¼ˆç”µå‹æˆ–é‡ç½®å¹…å€¼ï¼‰ç­‰ï¼Œä¼šå½±å“ç¥ç»å…ƒçš„å‘æ”¾é¢‘ç‡ã€æ—¶é—´å“åº”ã€æŠ‘åˆ¶æœºåˆ¶ç­‰ã€‚

        âœ… ç›®çš„ï¼šé€šè¿‡ä¸ºä¸åŒå±‚è®¾ç½®ä¸åŒç¥ç»å…ƒè¡Œä¸ºï¼Œè®©ç½‘ç»œåœ¨ä¸åŒé˜¶æ®µèƒ½å­¦ä¹ åˆ°æ›´åˆé€‚çš„æ—¶é—´åŠ¨æ€ã€‚
        ä¿®æ”¹æˆä¸¤å±‚
        
        """
        # ä¾æ¬¡å°†ä¸‰ä¸ªä¸åŒå±‚çš„ç¥ç»å…ƒå‚æ•°æ·»åŠ åˆ°ç©ºåˆ—è¡¨ self.neuron_config ä¸­
        self.neuron_config = []
        self.neuron_config.append(getNeuronConfig(theta=theta[0], tauSr=tauSr[0], tauRef=tauRef[0], scaleRef=scaleRef[0], tauRho=tauRho[0], scaleRho=scaleRho[0]))
        self.neuron_config.append(getNeuronConfig(theta=theta[1], tauSr=tauSr[1], tauRef=tauRef[1], scaleRef=scaleRef[1], tauRho=tauRho[1], scaleRho=scaleRho[1]))
        
        # å–å‚æ•°åˆ—è¡¨çš„ç¬¬0ä¸ªå…ƒç´ ï¼Œå³ç¬¬ä¸€ä¸ªç¥ç»å…ƒå‚æ•°ï¼Œè¿™ä¸ªé…ç½®ä¼šè¢«ä¼ å…¥ snn.layer(...)ï¼Œè¿™äº›å‚æ•°ä¼šå¯¹åº”èµ‹å€¼ç»™å…¶å†…éƒ¨çš„ç¥ç»å…ƒæ¨¡å‹
        # neuronDesc (slayerParams.yamlParams): spiking neuron descriptor.
        # simulationDesc (slayerParams.yamlParams): simulation descriptor
        self.slayer1 = snn.layer(self.neuron_config[0], netParams['simulation'])
        self.slayer2 = snn.layer(self.neuron_config[1], netParams['simulation'])
        

        # æ˜¯å·ç§¯å±‚ï¼Œç”±é…ç½®äº†å¯¹åº”å‚æ•°çš„ç»™è‡ªçš„ snn.layer æä¾›ï¼ˆslayer.pyä¸­å®šä¹‰äº†convå‡½æ•°ï¼Œå°±æ˜¯è°ƒç”¨slayer.pyä¸­convå‡½æ•°ï¼Œæƒ³è¦ä»€ä¹ˆå±‚ï¼Œå°±åœ¨slayer.pyä¸­å®šä¹‰ï¼‰ï¼Œå¸¦æœ‰è„‰å†²ç‰¹æ€§ã€‚
        self.conv1 = self.slayer1.conv(2, 8, 5, padding=2)
        
        self.upconv1 = self.slayer2.convTranspose(8, 2, kernelSize=4, stride=4)

    # è¿™æ®µ forward å‡½æ•°æ˜¯ NetworkBasic çš„å‰å‘ä¼ æ’­é€»è¾‘ï¼Œç”¨äºå¯¹è¾“å…¥çš„ è„‰å†²å¼ é‡ï¼ˆäº‹ä»¶æ•°æ®ï¼‰ è¿›è¡Œ æ—¶ç©ºå»ºæ¨¡å’Œä¸Šé‡‡æ ·é‡å»ºã€‚
    def forward(self, spikeInput):
        # é€šè¿‡ slayer1.psp() å¯¹è¾“å…¥è¿›è¡Œç”µå‹è†œç”µä½å»ºæ¨¡
        # print("=================================================================")
        # print(spikeInput.shape)
        psp1 = self.slayer1.psp(spikeInput)

        # è¾“å…¥ä¸º [B, C, H, W, T] å½¢çŠ¶çš„ 5D å¼ é‡ï¼Œè¡¨ç¤ºä¸€æ‰¹äº‹ä»¶æ•°æ®ï¼ˆè„‰å†²æµï¼‰ã€‚
        # H å’Œ W ä»ç„¶æ˜¯ç©ºé—´ä½ç½®ï¼Œä»£è¡¨ä¼ æ„Ÿå™¨åƒç´ ç½‘æ ¼ä¸Šçš„åæ ‡ã€‚
        # è·å–è¾“å…¥çš„ç»´åº¦
        B, C, H, W, T = spikeInput.shape
        # æŠŠæ—¶é—´ç»´åº¦ç§»åˆ°å‰é¢
        psp1_1 = psp1.permute((0, 1, 4, 2, 3))
        # åˆå¹¶æ—¶é—´å’Œé€šé“ï¼Œå˜æˆä¸€å †å›¾
        psp1_1 = psp1_1.reshape((B, C*T, H, W))
        # ç©ºé—´ä¸Šé‡‡æ · Ã—2. interpolate æ˜¯ PyTorch çš„æ’å€¼å‡½æ•°ï¼Œè¿™é‡Œç”¨ bilinear æ¨¡å¼å¯¹ ç©ºé—´ç»´åº¦ H å’Œ W ä¸Šé‡‡æ · 2 å€
        psp1_1 = torch.nn.functional.interpolate(psp1_1, scale_factor=4, mode='bilinear')
        # å†è½¬å›åŸæ¥çš„ç»´åº¦é¡ºåº.å°†å‰é¢åˆå¹¶çš„ C*T å†æ‹†å¼€ä¸º C å’Œ Tï¼Œå˜æˆ [B, C, T, 2H, 2W]ï¼Œ
        # ç„¶å permute æˆ [B, C, 2H, 2W, T]ï¼Œä¸ SNN çš„æ ‡å‡†è¾“å…¥ä¸€è‡´ã€‚
        psp1_1 = psp1_1.reshape(B, C, T, 4*H, 4*W).permute((0, 1, 3, 4, 2))

        # å°† PSP ç»“æœè¾“å…¥è„‰å†²å·ç§¯å±‚ï¼Œå¹¶ç”¨é˜ˆå€¼å‡½æ•°è½¬æ¢ä¸ºè„‰å†²è¾“å‡ºï¼ˆè„‰å†²è¡¨ç¤ºäº‹ä»¶æ˜¯å¦æ¿€æ´»ï¼‰ã€‚
        spikes_layer_1 = self.slayer1.spike(self.conv1(psp1))
        # å¯¹ä¸Šä¸€å±‚çš„è„‰å†²è¾“å‡ºç»§ç»­è¿›è¡Œ PSPï¼Œå†å·ç§¯ã€å†è„‰å†²ã€‚
        
        # PSP åä¸Šé‡‡æ ·ï¼Œç„¶åä¸å‰é¢æ—è·¯ä¸Šé‡‡æ ·çš„ psp1_1 ç›¸åŠ (åƒ ResNet çš„æ®‹å·®ï¼ŒåŠ å…¥ä¸€æ¡ç»†èŠ‚æ—è·¯è·¯å¾„)ï¼Œå†ç»è¿‡è„‰å†²å‘æ”¾ï¼Œè¾“å‡ºæœ€ç»ˆè„‰å†²ç»“æœã€‚
        spikes_layer_2 = self.slayer2.spike(self.upconv1(self.slayer2.psp(spikes_layer_1)) + psp1_1)

        # è¿™æ˜¯æ¨¡å‹å¯¹è¾“å…¥ä½åˆ†è¾¨ç‡äº‹ä»¶å¼ é‡çš„è¶…åˆ†é‡å»ºè¾“å‡ºã€‚
        # æœ€ç»ˆè¾“å‡ºå¤§å°ï¼šä» 32x32 â†’ 34x34ï¼ˆåªæ’å€¼ï¼Œä¸æ”¹å˜é€šé“å’Œæ—¶é—´ç»´åº¦ï¼‰
        # ğŸš¨ ä¿®æ­£æ’å€¼ç»´åº¦é”™è¯¯
        B, C, H, W, T = spikes_layer_2.shape

        # [B, C, H, W, T] â†’ [B, C, T, H, W]
        spikes_layer_2 = spikes_layer_2.permute(0, 1, 4, 2, 3)
        # [B, C, T, H, W] â†’ [B*T, C, H, W]
        spikes_layer_2 = spikes_layer_2.reshape(B * T, C, H, W)

        # âœ… ç©ºé—´æ’å€¼åˆ° 34Ã—34
        spikes_layer_2 = torch.nn.functional.interpolate(spikes_layer_2, size=(34, 34), mode='bilinear', align_corners=False)

        # [B*T, C, 34, 34] â†’ [B, T, C, 34, 34]
        spikes_layer_2 = spikes_layer_2.view(B, T, C, 34, 34)
        # â†’ [B, C, 34, 34, T]
        spikes_layer_2 = spikes_layer_2.permute(0, 2, 3, 4, 1)

        return spikes_layer_2




if __name__ == '__main__':
    import os
    from slayerSNN.spikeFileIO import event

    def readNpSpikes(filename, timeUnit=1e-3):
        npEvent = np.load(filename)
        return event(npEvent[:, 1], npEvent[:, 2], npEvent[:, 3], npEvent[:, 0] * timeUnit * 1e3)

#
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'

    x = readNpSpikes(r"D:\PycharmProjects\EventSR-dataset\dataset\N-MNIST\SR_Train\LR\0\1.npy")
    # è½¬åŒ–äº‹ä»¶æ•°æ®ä¸ºè„‰å†²å¼ é‡ï¼Œææ€§æåˆ°å‰é¢å½“åšä¸¤ä¸ªé€šé“ï¼ˆæ™®é€šå›¾åƒè½¬å¼ é‡çš„ç»´åº¦é¡ºåºéƒ½æ˜¯ç¬¬ä¸€ç»´åº¦ä¸ºé€šé“ç»´åº¦ï¼‰
    x = x.toSpikeTensor(torch.zeros((2, 17, 17, 350)))
    print(x)
    # å› ä¸ºä¸€ä¸ªè„‰å†²çš„ç»´åº¦æ˜¯5ä¸ªç»´åº¦ï¼Œæ‰€ä»¥åœ¨ç¬¬ 0 ä¸ªç»´åº¦ä¸Šæ’å…¥ä¸€ä¸ªå¤§å°ä¸º 1 çš„æ–°ç»´åº¦ã€‚
    x = torch.unsqueeze(x, dim=0).cuda()
    print(x)

    netParams = snn.params('./nMnist/network.yaml')
    m = NetworkBasic(netParams)
    m = torch.nn.DataParallel(m).cuda()
    with torch.no_grad():
        out = m(x)
    print((out == 0).sum(), (out == 1).sum(), ((out != 0) & (out != 1)).sum())

    # å¦‚æœæ˜¯åè€…ï¼Œè¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼Œæ˜¯æŒ‡è¾“å‡ºäº†å¹…å€¼ä¸º2 3 4çš„è„‰å†²ï¼Œè€Œä¸éƒ½æ˜¯å•ä½è„‰å†²ã€‚æˆ‘è®°å¾—slayersnnåº“è¾“å‡ºçš„spikeå¥½åƒæ˜¯æœ‰å¹…å€¼çš„ã€‚
    # åŒæ ·ï¼Œæˆ‘ä»¬è¾“å…¥çš„spikeæœ‰äº›ä¹Ÿæœ‰å¹…å€¼ï¼Œç”±äºæˆ‘ä»¬å°†åŸå§‹äº‹ä»¶æµæ²¿æ—¶é—´ç»´åº¦å †å åˆ°tSampleä¸ªchannelï¼ˆe.g., tSample=350 for nMNIST datasetï¼‰ï¼Œ
    # åœ¨å‹ç¼©è¿‡ç¨‹ä¸­ï¼Œå¦‚çŸ­æ—¶é—´å†…åŒä¸€åƒç´ ç‚¹è§¦å‘å¤šä¸ªeventï¼Œä¼šå †å æˆä¸€ä¸ªå€æ•°å¹…å€¼çš„spikeã€‚