"""
è¿™æ®µä»£ç æ˜¯è®­ç»ƒé€»è¾‘å’Œæ‰“å°ç»“æœ
è®­ç»ƒé€»è¾‘ï¼š
1.æ¨¡å‹å‰å‘ä¼ æ’­ï¼Œè¾“å‡ºç»“æœã€‚
output = m(eventLr)

2.è®¡ç®—æŸå¤±å‡½æ•°ã€‚
å…¶ä¸­ä¸€ä¸ªlossæ˜¯loss = MSE(output, eventHr)

3.åå‘ä¼ æ’­ï¼Œæ›´æ–°å‚æ•°ã€‚
# æ¸…ç©ºæ—§æ¢¯åº¦ã€‚ç”¨optimizerçš„åŠŸèƒ½ï¼Œä¼˜åŒ–å™¨åœ¨110è¡Œå®šä¹‰ï¼šoptimizer = torch.optim.Adam(m.parameters(), lr=args.lr, amsgrad=True)
optimizer.zero_grad()
# åå‘ä¼ æ’­è®¡ç®—æ–°æ¢¯åº¦ã€‚é€šè¿‡å…ˆå®šä¹‰å‡ºæ¥loss_totalï¼Œç”¨backward()è®¡ç®—æ¢¯åº¦ï¼Œå†é€šè¿‡optimizer.step()æ›´æ–°å‚æ•°ã€‚
loss_total.backward()
# æ›´æ–°å‚æ•°ã€‚
optimizer.step()

éªŒè¯é˜¶æ®µï¼š
éªŒè¯é˜¶æ®µç”¨äºè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œä¸è¿›è¡Œæ¢¯åº¦æ›´æ–°å’Œå‚æ•°ä¼˜åŒ–ï¼Œä»…å‰å‘ä¼ æ’­å¹¶è®°å½•è¯„ä¼°æŒ‡æ ‡ã€‚

"""


import sys
import os
import datetime
import torch
from torch.utils.data import DataLoader
from tensorboardX import SummaryWriter

sys.path.append('../')
from åºŸå¼ƒ.model_1 import NetworkBasic
from åºŸå¼ƒ.mnistDatasetSR_1 import mnistDataset
from utils.ckpt import checkpoint_restore, checkpoint_save
from opts import parser
from statistic import Metric
import slayerSNN as snn




def main():
    """
    parseræ˜¯ä¸€ä¸ª å‘½ä»¤è¡Œå‚æ•°è§£æå™¨å¯¹è±¡
    parse_args() æ˜¯åœ¨å‘Šè¯‰å®ƒï¼šâ€œç°åœ¨è¯·è§£æå‘½ä»¤è¡Œä¸­çœŸæ­£ä¼ è¿›æ¥çš„å€¼â€
    args = parser.parse_args()è§£æå‚æ•°ï¼Œä¼šåšä¸¤ä»¶äº‹ï¼š
    1.ä»ç³»ç»Ÿä¸­è¯»å–å‘½ä»¤è¡Œå‚æ•°ï¼ˆå³ sys.argvï¼‰ï¼Œå¹¶è§£æå®ƒä»¬
    ä¾‹å¦‚ï¼š.batæ–‡ä»¶æ˜¯python trainNmnist.py --bs 64 --lr 0.1
    æ­¤æ—¶ sys.argv çš„å€¼æ˜¯ï¼š['trainNmnist.py', '--bs', '64', '--lr', '0.1']
    2.æŠŠè¿™äº›å‚æ•°è‡ªåŠ¨â€œåŒ¹é…â€åˆ°ä½  .add_argument() æ³¨å†Œè¿‡çš„å‚æ•°é‡Œï¼Œå¹¶è‡ªåŠ¨è½¬æ¢ç±»å‹ã€å¤„ç†é»˜è®¤å€¼ç­‰
    ä¾‹å¦‚ï¼šargs.bs  # = 64
        args.lr  # = 0.1

    ä¾‹å¦‚ï¼š.bat æ–‡ä»¶å†™ï¼špython trainNmnist.py --bs 64
    æœ€ç»ˆ args.bs == 64 âœ…

    æ€»ç»“ï¼š
    train.bat â†’ å‘½ä»¤è¡Œå‚æ•° â†’ trainNmnist.py â†’ parser.parse_args() â†’ args
    å‚æ•°ä¼ é€’æ˜¯éšå¼çš„
    ä½ ä¸ä¼šåœ¨ä»£ç ä¸­å†™ï¼šargs = parser.parse_args(['--bs', '64'])  âŒ
    è€Œæ˜¯è®©ç³»ç»Ÿâ€œè‡ªåŠ¨â€æŠŠå‘½ä»¤è¡Œä¸­çš„ï¼špython trainNmnist.py --bs 64 --lr 0.1
    å˜æˆå†…éƒ¨çš„ï¼šsys.argv = ['trainNmnist.py', '--bs', '64', '--lr', '0.1']
    argparse é»˜è®¤å°±æ˜¯è§£æè¿™ä¸ª sys.argvï¼Œæ‰€ä»¥ä½ ä¸éœ€è¦æ˜¾å¼ä¼ é€’ï¼Œç§°ä¹‹ä¸ºâ€œéšå¼ä¼ å‚â€æ˜¯éå¸¸åˆç†çš„ âœ…ã€‚
    .bat æ–‡ä»¶ä¸­å†™çš„å‚æ•°æ˜¯é€šè¿‡ç³»ç»Ÿè°ƒç”¨è‡ªåŠ¨ä¼ é€’åˆ° Python çš„ sys.argv ä¸­çš„ï¼Œ
    argparseä¼šéšå¼è§£æè¿™äº›å€¼å¹¶è½¬æ¢ç±»å‹ã€è®¾å®šé»˜è®¤å€¼ï¼Œä»è€Œä½¿å¾—ä½ çš„ Python è„šæœ¬æ— éœ€æ‰‹åŠ¨è¯»å–å‘½ä»¤è¡Œå‚æ•°å°±å¯ä»¥ç›´æ¥ç”¨ã€‚

    """
    args = parser.parse_args()
    # å®šä¹‰æ¨¡å‹è¾“å…¥çš„å½¢çŠ¶
    shape = [34, 34, 350]
    # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ŒæŒ‡å®šä½¿ç”¨å“ªä¸€å—GPU
    os.environ["CUDA_VISIBLE_DEVICES"] = args.cuda
    # è®¾ç½®è®¾å¤‡ä¸ºGPU
    device = 'cuda'

    # åˆ›å»ºè®­ç»ƒæ•°æ®é›†ï¼Œè¯»å–è®­ç»ƒæ•°æ®é›†æ–‡ä»¶è·¯å¾„
    trainDataset = mnistDataset()
    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†ï¼Œè¯»å–è®­ç»ƒæµ‹è¯•é›†æ–‡ä»¶è·¯å¾„ï¼ˆFalseè¡¨æ˜æ˜¯æµ‹è¯•é›†ï¼‰
    testDataset = mnistDataset(False)

    print("Training sample: %d, Testing sample: %d" % (len(trainDataset), len(testDataset)))
    # è·å–å‘½ä»¤è¡Œå‚æ•°ï¼ˆtrain.batï¼‰ä¸­çš„batch size
    bs = args.bs

    # ä½¿ç”¨ PyTorch ä¸­çš„ DataLoader æ¥åˆ›å»ºè®­ç»ƒé›†æ•°æ®åŠ è½½å™¨ï¼Œbatch_sizeä¸ºbsï¼Œ
    # shuffleä¸ºTrue(è¡¨ç¤ºåœ¨æ¯ä¸ªè®­ç»ƒè½®æ¬¡å¼€å§‹å‰ï¼Œéšæœºæ‰“ä¹±æ•°æ®é¡ºåºï¼Œé˜²æ­¢æ¨¡å‹è®°ä½æ•°æ®æ’åˆ—ï¼Œä»è€Œæé«˜æ³›åŒ–èƒ½åŠ›)ï¼Œ
    # num_workersä¸ºargs.jï¼Œä½¿ç”¨ j=4 ä¸ªå­è¿›ç¨‹ï¼ˆçº¿ç¨‹ï¼‰æ¥å¹¶è¡ŒåŠ è½½æ•°æ®
    # drop_lastä¸ºTrue,å‡è®¾ä½ è®­ç»ƒé›†ä¸­æœ‰ 10,000 ä¸ªæ ·æœ¬ï¼Œbatch size æ˜¯ 64, å¦‚æœ drop_last=Trueï¼Œæœ€åçš„ ä¸è¶³ 64 ä¸ªæ ·æœ¬ä¼šè¢«ä¸¢å¼ƒã€‚
    # å¦‚æœ drop_last=Falseï¼Œæœ€åçš„ batch å¯èƒ½æ˜¯ 10000 % 64 = 16 ä¸ªæ ·æœ¬ã€‚
    # è®­ç»ƒæ—¶è¿›è¡Œ æ¢¯åº¦åå‘ä¼ æ’­ï¼Œæ¯ä¸ª batch è¦æ±‚ shape ä¸€è‡´,æ‰€ä»¥ drop_last=Trueï¼›æµ‹è¯•ä¸éœ€è¦æ¢¯åº¦å›ä¼ ï¼Œå¯¹ batch å°ºå¯¸è¦æ±‚æ²¡é‚£ä¹ˆä¸¥
    trainLoader = DataLoader(dataset=trainDataset, batch_size=bs, shuffle=True, num_workers=args.j, drop_last=True)
    testLoader = DataLoader(dataset=testDataset, batch_size=bs, shuffle=True, num_workers=args.j, drop_last=False)

    # snn æ˜¯ä¸€ä¸ªå·¥å…·åº“ï¼Œä¸“é—¨ç”¨äºæ­å»ºå’Œè®­ç»ƒ SNN
    # ä» network.yaml ä¸­è¯»å– SNN çš„ä»¿çœŸå‚æ•°ï¼ˆå¦‚ Ts æ—¶é—´æ­¥é•¿ã€tSample æ€»æ—¶é—´çª—ï¼‰ï¼Œå¹¶è¿”å›ä¸€ä¸ªå‚æ•°å­—å…¸æˆ–å¯¹è±¡ï¼Œä¾› NetworkBasic åˆå§‹åŒ–æ—¶ä½¿ç”¨ã€‚
    netParams = snn.params('../nMnist/network.yaml')
    # è°ƒç”¨æ¨¡å‹ç±»ï¼Œåˆ›å»ºç½‘ç»œå¯¹è±¡
    m = NetworkBasic(netParams)
    # å°†ç½‘ç»œè½¬æ¢ä¸ºå¹¶è¡Œè®¡ç®—æ¨¡å¼ï¼Œå¹¶å°†å…¶ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡ä¸Š
    m = torch.nn.DataParallel(m).to(device)

    # æ‰“å°ç½‘ç»œ
    print(m)


    # å®šä¹‰å‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°
    MSE = torch.nn.MSELoss()
    # å®šä¹‰Adamä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ä¸ºargs.lrï¼Œamsgradä¸ºTrue
    # â€œä¼˜åŒ–â€å°±æ˜¯é€šè¿‡åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦ï¼Œå¹¶ç”¨ä¼˜åŒ–å™¨ï¼ˆå¦‚ Adamï¼‰æ ¹æ®è¿™äº›æ¢¯åº¦æ›´æ–°ç¥ç»ç½‘ç»œçš„å‚æ•°ï¼Œä»¥ä½¿æŸå¤±å‡½æ•°å°½å¯èƒ½å‡å°ã€‚
    # m.parameters() è¡¨ç¤ºæ¨¡å‹ m ä¸­æ‰€æœ‰éœ€è¦è®­ç»ƒçš„å‚æ•°ï¼ˆå¦‚æƒé‡å’Œåç½®ï¼‰ï¼Œæ˜¯ä¼˜åŒ–å™¨æ›´æ–°çš„å¯¹è±¡ã€‚
    optimizer = torch.optim.Adam(m.parameters(), lr=args.lr, amsgrad=True)


    # è®¡ç®—æ¯ä¸ªepochçš„è¿­ä»£æ¬¡æ•°ã€‚è®­ç»ƒé›†æ ·æœ¬æ€»æ•°â—bsï¼Œç»“æœæ˜¯ æ¯ä¸ª epoch éœ€è¦å‡ ä¸ª batch æ‰èƒ½è·‘å®Œæ‰€æœ‰æ ·æœ¬ã€‚å¦‚æœè®­ç»ƒé›†æœ‰ 1000 ä¸ªæ ·æœ¬ï¼Œbs = 100ã€‚å°±æ˜¯è¯´ï¼Œæ¯ä¸ª epoch è¦è¿­ä»£ 10 æ¬¡ã€‚
    # Batch size æ˜¯æ¯æ¬¡é€å…¥æ¨¡å‹è®­ç»ƒçš„ä¸€å°æ‰¹æ•°æ®çš„æ•°é‡ã€‚Epoch æ˜¯æ•´ä¸ªè®­ç»ƒé›†è¢«å®Œæ•´è®­ç»ƒä¸€éçš„æ¬¡æ•°ã€‚
    iter_per_epoch = len(trainDataset) // bs
    # è·å–å½“å‰æ—¶é—´
    time_last = datetime.datetime.now()

    # åˆ›å»ºä¿å­˜æ–‡ä»¶çš„æ—¶é—´æˆ³å”¯ä¸€æ ‡è¯†æ–‡ä»¶å
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    # åˆ›å»ºæ¨¡å‹ä¿å­˜è·¯å¾„ï¼Œæ ¹æ®å‘½ä»¤è¡Œå‚æ•°.batä¸­çš„savepathï¼Œæ–‡ä»¶åæ ‡è¯†è®­ç»ƒå‚æ•°
    savePath = os.path.join(
        args.savepath,
        f"bs{args.bs}_lr{args.lr}_ep{args.epoch}_cuda{args.cuda}_{timestamp}"
    )

    # åˆ›å»ºä¿å­˜è·¯å¾„ï¼Œå¦‚æœè·¯å¾„å·²å­˜åœ¨åˆ™ä¸æŠ¥é”™ï¼ˆä¸ä¼šè¦†ç›–å·²æœ‰åŒåæ–‡ä»¶ï¼Œå¦‚æœç›®æ ‡æ–‡ä»¶å¤¹å·²ç»å­˜åœ¨ï¼Œå®ƒå°±ä»€ä¹ˆéƒ½ä¸åšã€‚ï¼‰
    os.makedirs(savePath, exist_ok=True)

    # ä»savePathè·¯å¾„ä¸­æ¢å¤æ¨¡å‹må’Œepoch0
    # m, epoch0 = checkpoint_restore(m, savePath)
    #ç”¨ä¸åŒçš„ --savepath(train.batæ”¹è·¯å¾„) å¼€å¯å…¨æ–°è®­ç»ƒï¼›å¦‚æœä»¥åè¿™ä¸ªæ–‡ä»¶å¤¹é‡Œæœ‰ ckpt.pthï¼Œåˆèƒ½è‡ªåŠ¨ç»­è®­ï¼Œä¸¤è€…å…¼å®¹ã€‚
    ckpt_file = os.path.join(savePath, 'ckpt.pth')
    if os.path.exists(ckpt_file):
        m, epoch0 = checkpoint_restore(m, savePath)
    else:
        print("[INFO] No checkpoint found. Starting training from scratch.")
        epoch0 = -1  # ä»å¤´å¼€å§‹è®­ç»ƒ

    # è®¾ç½®æœ€å¤§è®­ç»ƒè½®æ•°
    maxEpoch = args.epoch
    # è®¾ç½®æ˜¾ç¤ºé¢‘ç‡
    showFreq = args.showFreq
    # åˆå§‹åŒ–éªŒè¯æŸå¤±å†å²è®°å½•
    valLossHistory = []
    # åˆ›å»ºTensorBoardå†™å…¥å™¨
    tf_writer = SummaryWriter(log_dir=savePath)

    # æ‰“å¼€ä¿å­˜è·¯å¾„ä¸‹çš„config.txtæ–‡ä»¶ï¼Œä»¥å†™å…¥æ¨¡å¼æ‰“å¼€
    with open(os.path.join(savePath, 'config.txt'), 'w') as f:
        # éå†m.module.neuron_configä¸­çš„æ¯ä¸€ä¸ªconfig
        for i, config in enumerate(m.module.neuron_config):
            # å°†configä¸­çš„å‚æ•°å†™å…¥æ–‡ä»¶
            f.writelines('layer%d: theta=%d, tauSr=%.2f, tauRef=%.2f, scaleRef=%.2f, tauRho=%.2f, scaleRho=%.2f\n' % (
                i + 1, config['theta'], config['tauSr'], config['tauRef'], config['scaleRef'], config['tauRho'], config['scaleRho']))
        # å†™å…¥ä¸€ä¸ªç©ºè¡Œ
        f.writelines('\n')
        # å°†argså†™å…¥æ–‡ä»¶
        f.write(str(args))

    # æ‰“å¼€ä¿å­˜è·¯å¾„ä¸‹çš„log.csvæ–‡ä»¶ï¼Œä»¥å†™å…¥æ¨¡å¼æ‰“å¼€
    log_training = open(os.path.join(savePath, 'log.csv'), 'w')

    # è¿™æ®µä»£ç æ˜¯ä½ æ¨¡å‹çš„è®­ç»ƒä¸»å¾ªç¯ï¼Œæ¯ä¸€è½®ï¼ˆepochï¼‰ä¸­éƒ½ä¼šè¿›è¡Œè®­ç»ƒå’ŒéªŒè¯
    for epoch in range(epoch0 + 1, maxEpoch):
        trainMetirc = Metric()
        m.train()
        # è®­ç»ƒé˜¶æ®µï¼ˆæ¯ epochï¼‰
        for i, (eventLr_pos, eventLr_neg, eventHr) in enumerate(trainLoader, 0):
            # eventLr, eventHr æ˜¯ä½åˆ†è¾¨ç‡å’Œé«˜åˆ†è¾¨ç‡äº‹ä»¶å¼ é‡ã€‚
            # eventLr, eventHr æ˜¯ä» trainDataset ä¸­æŒ‰æ‰¹åŠ è½½çš„æ•°æ®
            # å®ƒä»¬æ¥è‡ªä½ è‡ªå®šä¹‰çš„ mnistDataset ç±»çš„è¿”å›ç»“æœ
            # é€šå¸¸æ˜¯å½¢å¦‚ [B, 2, H, W, T] çš„ 5D å¼ é‡å¯¹ï¼Œç”¨äºè¶…åˆ†ä»»åŠ¡è®­ç»ƒ
            eventLr_pos, eventLr_neg, eventHr = eventLr_pos.to(device), eventLr_neg.to(device), eventHr.to(device)
            # æ¨¡å‹å‰å‘ä¼ æ’­ï¼Œè¾“å‡ºç»“æœã€‚

            output_pos = m(eventLr_pos)
            # print("===============================")
            # print("ğŸŸ¢ output_pos:")
            # print("  shape:", output_pos.shape)
            # print("  non-zero spikes:", (output_pos != 0).sum().item())

            output_neg = m(eventLr_neg)
            # print("ğŸ”µ output_neg:")
            # print("  shape:", output_neg.shape)
            # print("  non-zero spikes:", (output_neg != 0).sum().item())

            # output = 0.5 * (output_pos + output_neg)
            output = output_pos + output_neg
            # print("ğŸŸ£ output (combined):")
            # print("  shape:", output.shape)
            # print("  non-zero spikes:", (output != 0).sum().item())


            # è®¡ç®—æŸå¤±å‡½æ•°ã€‚
            loss = MSE(output, eventHr)
            loss_ecm = sum([MSE(torch.sum(output[:, :, :, :, i*50:(i+1)*50], dim=4),
                                torch.sum(eventHr[:, :, :, :, i*50:(i+1)*50], dim=4)) for i in range(shape[2] // 50)])
            loss_total = loss + loss_ecm * 5

            # æ¸…ç©ºæ—§æ¢¯åº¦ã€‚
            optimizer.zero_grad()
            # åå‘ä¼ æ’­è®¡ç®—æ–°æ¢¯åº¦ã€‚
            loss_total.backward()
            # æ›´æ–°å‚æ•°ã€‚
            optimizer.step()

            # è®­ç»ƒè¿›åº¦è®°å½•ã€‚æ¯ showFreq æ¬¡è¿­ä»£ï¼Œè®°å½•ä¸€æ¬¡å½“å‰æŒ‡æ ‡ï¼Œå¦‚æŸå¤±ã€è„‰å†²æ•°é‡ã€é¢„è®¡å‰©ä½™è®­ç»ƒæ—¶é—´ã€‚
            if i % showFreq == 0:
                trainMetirc.updateIter(loss.item(), loss_ecm.item(), loss_total.item(), 1,
                                       eventLr_pos.sum().item() + eventLr_neg.sum().item(), output.sum().item(), eventHr.sum().item())
                print_progress(epoch, maxEpoch, i, iter_per_epoch, bs, trainMetirc, time_last, "Train", log_training)
                time_last = datetime.datetime.now()

        log_tensorboard(tf_writer, trainMetirc, epoch, prefix="Train")
        log_epoch_done(log_training, epoch)

        #  éªŒè¯é˜¶æ®µï¼ˆæ¯ epochï¼‰
        if epoch % 1 == 0:
            # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ã€‚
            m.eval()
            t = datetime.datetime.now()
            valMetirc = Metric()
            for i, (eventLr_pos, eventLr_neg, eventHr) in enumerate(testLoader, 0):
                # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼Œæé«˜æ¨ç†é€Ÿåº¦
                with torch.no_grad():
                    eventLr_pos, eventLr_neg, eventHr = eventLr_pos.to(device), eventLr_neg.to(device), eventHr.to(device)

                    output_pos = m(eventLr_pos)
                    print("=============validation==================")
                    print("ğŸŸ¢ output_pos:")
                    print("  shape:", output_pos.shape)
                    print("  non-zero spikes:", (output_pos != 0).sum().item())

                    output_neg = m(eventLr_neg)
                    print("ğŸ”µ output_neg:")
                    print("  shape:", output_neg.shape)
                    print("  non-zero spikes:", (output_neg != 0).sum().item())
                    # output = 0.5 * (output_pos + output_neg)


                    output = output_pos + output_neg
                    print("ğŸŸ£ output (combined):")
                    print("  shape:", output.shape)
                    print("  non-zero spikes:", (output != 0).sum().item())



                    loss = MSE(output, eventHr)
                    loss_ecm = sum([MSE(torch.sum(output[:, :, :, :, i*50:(i+1)*50], dim=4),
                                        torch.sum(eventHr[:, :, :, :, i*50:(i+1)*50], dim=4)) for i in range(shape[2] // 50)])
                    loss_total = loss + loss_ecm
                    #  å°†å½“å‰éªŒè¯è½®æ¬¡ä¸­ä¸€ä¸ª batch çš„å„ç±»æŒ‡æ ‡ä¼ å…¥ valMetirc è¿›è¡Œç»Ÿè®¡ä¸è®°å½•ï¼Œç”¨äºåç»­è®¡ç®—å¹³å‡æŸå¤±ã€è„‰å†²æ•°é‡ç­‰è¯„ä¼°ç»“æœã€‚
                    valMetirc.updateIter(loss.item(), loss_ecm.item(), loss_total.item(), 1,
                                         eventLr_pos.sum().item() + eventLr_neg.sum().item(), output.sum().item(), eventHr.sum().item())

                    if i % showFreq == 0:
                        print_progress(epoch, maxEpoch, i, len(testDataset) // bs, bs, valMetirc, time_last, "Val", log_training)
                        time_last = datetime.datetime.now()

            log_tensorboard(tf_writer, valMetirc, epoch, prefix="Val")
            log_validation_summary(valMetirc, valLossHistory, epoch, t, log_training, savePath, m, device)

        # å­¦ä¹ ç‡è¡°å‡ï¼ˆæ¯15è½®ï¼‰ï¼Œå°†å­¦ä¹ ç‡ç¼©å°ä¸ºåŸæ¥çš„ 0.1 å€ï¼ŒåŠ å¿«æ”¶æ•›ã€‚
        if (epoch + 1) % 15 == 0:
            for param_group in optimizer.param_groups:
                param_group['lr'] *= 0.1
                print("Learning rate decreased to:", param_group['lr'])


# ç”¨äºæ‰“å°è®­ç»ƒæˆ–æµ‹è¯•è¿‡ç¨‹ä¸­çš„è¿›åº¦ä¿¡æ¯
def print_progress(epoch, maxEpoch, i, total, bs, metric, time_last, mode, log_file):
    remainIter = (maxEpoch - epoch - 1) * total + (total - i - 1)
    now = datetime.datetime.now()
    dt = (now - time_last).total_seconds()
    remainSec = remainIter * dt
    h, remain = divmod(remainSec, 3600)
    m, s = divmod(remain, 60)
    end_time = now + datetime.timedelta(seconds=remainSec)
    avgLossTime, avgLossEcm, avgLoss, avgIS, avgOS, avgGS = metric.getAvg()
    msg = f'{mode}, Cost {dt:.1f}s, Epoch[{epoch}], Iter {i}/{total}, Time Loss: {avgLossTime:.6f}, ' \
          f'Ecm Loss: {avgLossEcm:.6f}, Avg Loss: {avgLoss:.6f}, bs: {bs}, IS: {avgIS}, OS: {avgOS}, GS: {avgGS}, ' \
          f'Remain time: {int(h):02d}:{int(m):02d}:{int(s):02d}, End at: {end_time:%Y-%m-%d %H:%M:%S}'
    print(msg)
    if log_file is not None:
        log_file.write(msg + '\n')
        log_file.flush()

# ç”¨äºå°†è®­ç»ƒæˆ–æµ‹è¯•è¿‡ç¨‹ä¸­çš„å„ç§æŒ‡æ ‡ï¼ˆå¦‚æŸå¤±ã€è¾“å…¥å’Œè¾“å‡ºè„‰å†²æ•°é‡ï¼‰è®°å½•åˆ° TensorBoard ä¸­ï¼Œä»¥ä¾¿è¿›è¡Œå¯è§†åŒ–åˆ†æã€‚
def log_tensorboard(writer, metric, epoch, prefix="Train"):
    avgLossTime, avgLossEcm, avgLoss, avgIS, avgOS, avgGS = metric.getAvg()
    writer.add_scalar(f'loss/{prefix}_Time_Loss', avgLossTime, epoch)
    writer.add_scalar(f'loss/{prefix}_Spatial_Loss', avgLossEcm, epoch)
    writer.add_scalar(f'loss/{prefix}_Total_Loss', avgLoss, epoch)
    writer.add_scalar(f'SpikeNum/{prefix}_Input', avgIS, epoch)
    writer.add_scalar(f'SpikeNum/{prefix}_Output', avgOS, epoch)
    writer.add_scalar(f'SpikeNum/{prefix}_GT', avgGS, epoch)

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè®°å½•æ¯ä¸ªepochå®Œæˆçš„ä¿¡æ¯
def log_epoch_done(log_file, epoch):
    # å®šä¹‰ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒåŒ…å«50ä¸ªè¿å­—ç¬¦ï¼Œepochçš„å€¼ï¼Œä»¥åŠ50ä¸ªè¿å­—ç¬¦
    msg = '-' * 50 + f"Epoch {epoch} Done" + '-' * 50
    # æ‰“å°è¯¥å­—ç¬¦ä¸²
    print(msg)
    # å¦‚æœlog_fileä¸ä¸ºç©ºï¼Œåˆ™å°†å­—ç¬¦ä¸²å†™å…¥log_fileï¼Œå¹¶åˆ·æ–°log_file
    if log_file is not None:
        log_file.write(msg + '\n')
        log_file.flush()

# ç”¨äºåœ¨éªŒè¯è¿‡ç¨‹ä¸­è®°å½•å’Œä¿å­˜æ¨¡å‹çš„æ€§èƒ½æŒ‡æ ‡å’Œæ£€æŸ¥ç‚¹ã€‚å®ƒæ¥å—å¤šä¸ªå‚æ•°ï¼ŒåŒ…æ‹¬éªŒè¯æŒ‡æ ‡ã€éªŒè¯æŸå¤±å†å²è®°å½•ã€å½“å‰ epochã€å¼€å§‹æ—¶é—´ã€æ—¥å¿—æ–‡ä»¶ã€ä¿å­˜è·¯å¾„ã€æ¨¡å‹å’Œè®¾å¤‡ã€‚
# å‡½æ•°ä¼šè®¡ç®—å¹³å‡æŸå¤±å’Œæ—¶é—´ï¼Œæ‰“å°å’Œè®°å½•éªŒè¯ç»“æœï¼Œå¹¶ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹ã€‚å¦‚æœå½“å‰æŸå¤±æ˜¯æœ€ä½çš„ï¼Œè¿˜ä¼šä¿å­˜ä¸€ä¸ªæœ€ä½³çš„æ£€æŸ¥ç‚¹ã€‚
def log_validation_summary(metric, valLossHistory, epoch, t_start, log_file, savePath, model, device):
    avgLossTime, avgLossEcm, avgLoss, *_ = metric.getAvg()
    valLossHistory.append(avgLoss)
    t_end = datetime.datetime.now()
    msg = f"Validation Done! Cost Time: {(t_end - t_start).total_seconds():.2f}s, " \
          f"Loss Time: {avgLossTime:.6f}, Loss Ecm: {avgLossEcm:.6f}, Avg Loss: {avgLoss:.6f}, " \
          f"Min Val Loss: {min(valLossHistory):.6f}\n"
    print(msg)
    if log_file is not None:
        log_file.write(msg + '\n')
        log_file.flush()

    # ä¿å­˜æ¨¡å‹
    checkpoint_save(model=model, path=savePath, epoch=epoch, name="ckpt", device=device)
    # å¦‚æœå¹³å‡æŸå¤±ç­‰äºéªŒè¯æŸå¤±å†å²ä¸­çš„æœ€å°å€¼ï¼Œåˆ™ä¿å­˜æ¨¡å‹
    if avgLoss == min(valLossHistory):
        checkpoint_save(model=model, path=savePath, epoch=epoch, name="ckptBest", device=device)
    # æ‰“å¼€æ—¥å¿—æ–‡ä»¶ï¼Œä»¥è¿½åŠ æ–¹å¼å†™å…¥
    with open(os.path.join(savePath, 'log.txt'), "a") as f:
        # å†™å…¥å½“å‰epochçš„æŸå¤±å€¼
        f.write(f"Epoch: {epoch}, Ecm loss: {avgLossEcm:.6f}, Spike time loss: {avgLossTime:.6f}, Total loss: {avgLoss:.6f}\n")

if __name__ == '__main__':
    import torch.multiprocessing
    torch.multiprocessing.freeze_support()
    main()
