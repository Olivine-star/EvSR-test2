"""
è¿™ä¸€æ®µä»£ç çš„ä½œç”¨æ˜¯ï¼š
1.è¾“å…¥eventLrï¼Œä½åˆ†è¾¨ç‡äº‹ä»¶
2.è°ƒç”¨æ¨¡å‹ï¼Œå¯¹ä½åˆ†è¾¨ç‡äº‹ä»¶eventLrè¿›è¡Œé¢„æµ‹ï¼Œå¾—åˆ°é«˜åˆ†è¾¨ç‡äº‹ä»¶ä¿å­˜ä¸ºsavepathï¼ˆdataset_path.txtï¼‰ä¸‹çš„.npyæ–‡ä»¶
"""


import sys
sys.path.append('..')
from åºŸå¼ƒ.model_1 import NetworkBasic
from torch.utils.data import DataLoader, Dataset
import os
import slayerSNN as snn
import torch
from utils.utils import getEventFromTensor
from utils.ckpt import checkpoint_restore
import numpy as np
from slayerSNN.spikeFileIO import event


os.environ["CUDA_VISIBLE_DEVICES"] = "0"
device = 'cuda'


def readNpSpikes(filename, split_polarity=False, timeUnit=1e-3):
    npEvent = np.load(filename)

    if split_polarity:
        pos = npEvent[npEvent[:, 3] == 1]
        neg = npEvent[npEvent[:, 3] == 0]
        

        ev_pos = event(pos[:, 1], pos[:, 2], pos[:, 3], pos[:, 0] * timeUnit * 1e3)
        ev_neg = event(neg[:, 1], neg[:, 2], neg[:, 3], neg[:, 0] * timeUnit * 1e3)




        return ev_pos, ev_neg  # æ–°å¢åŸå§‹æ•°ç»„è¿”å›
    else:
        return event(npEvent[:, 1], npEvent[:, 2], npEvent[:, 3], npEvent[:, 0] * timeUnit * 1e3)


# -------------------------------
# âœ… è·¯å¾„è¯»å–å‡½æ•°ï¼ˆå†…è”ï¼‰
# -------------------------------
def load_path_config(path_config='dataset_path.txt'):
    path_dict = {}
    with open(path_config, 'r') as f:
        for line in f:
            if '=' in line:
                key, val = line.strip().split('=', 1)
                path_dict[key.strip()] = val.strip()
    return path_dict

# -------------------------------
# âœ… åŠ è½½è·¯å¾„é…ç½®
# -------------------------------
paths = load_path_config()
savepath = paths.get('savepath', '')
ckptPath = paths.get('ckptPath', '')


class mnistDataset(Dataset):
    def __init__(self):
        self.lrList = []
        self.hrList = []
        self.hrPath = paths.get('test_hr', '')
        self.lrPath = paths.get('test_lr', '')
        self.path = []

        self.H = 34
        self.W = 34

        for k in range(10):
            print("Read data %d"%k)
            hp = os.path.join(self.hrPath, str(k))
            lp = os.path.join(self.lrPath, str(k))
            if not os.path.exists(os.path.join(savepath, str(k))):
                os.makedirs(os.path.join(savepath, str(k)))
            assert len(os.listdir(hp)) == len(os.listdir(lp))
            list = os.listdir(hp)
            for n in list:
                self.hrList.append(os.path.join(hp, n))
                self.lrList.append(os.path.join(lp, n))
                self.path.append(os.path.join(str(k), n))

        self.nTimeBins = 350

    def __getitem__(self, idx):
        

        # è¯»å–é«˜åˆ†è¾¨ç‡äº‹ä»¶åˆ—è¡¨ä¸­çš„ç¬¬idxä¸ªäº‹ä»¶,readNpSpikes å‡½æ•°ç”¨äºè¯»å–è¿™äº›æ–‡ä»¶ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸º event å¯¹è±¡
        # ğŸ‘‰ ä½åˆ†è¾¨ç‡äº‹ä»¶ï¼šåˆ†å¼€æ­£è´Ÿææ€§
        eventLr_pos, eventLr_neg = readNpSpikes(self.lrList[idx], split_polarity=True)

        # ğŸ‘‰ ä¿è¯ææ€§ä¸ºé€šé“ 0
        eventLr_pos.p[:] = 0
        eventLr_neg.p[:] = 0

        # ğŸ‘‰ é«˜åˆ†è¾¨ç‡äº‹ä»¶ï¼šæ•´ä½“è¯»å–ï¼Œä¸åˆ†ææ€§
        eventHr = readNpSpikes(self.hrList[idx], split_polarity=False)

        # è½¬ä¸º spike tensorï¼ˆä½åˆ†è¾¨ç‡ä¸¤ä¸ªææ€§é€šé“ï¼‰
        eventLr_pos_tensor = eventLr_pos.toSpikeTensor(torch.zeros((1, 17, 17, self.nTimeBins)))
        eventLr_neg_tensor = eventLr_neg.toSpikeTensor(torch.zeros((1, 17, 17, self.nTimeBins)))


        # é«˜åˆ†è¾¨ç‡äº‹ä»¶ç›´æ¥è½¬å¼ é‡ï¼ˆé»˜è®¤å«æ­£è´Ÿææ€§ï¼‰
        eventHr_tensor = eventHr.toSpikeTensor(torch.zeros((2, 34, 34, self.nTimeBins)))

        # æ ¡éªŒ


        assert eventLr_pos_tensor.sum() == len(eventLr_pos.x)
        assert eventLr_neg_tensor.sum() == len(eventLr_neg.x)
        
        assert eventHr_tensor.sum() == len(eventHr.x)

        path = self.path[idx]
        return eventLr_pos_tensor, eventLr_neg_tensor, eventHr_tensor, path

    def __len__(self):
        return len(self.lrList)


# åˆ›å»ºä¸€ä¸ªmnistDatasetå¯¹è±¡
testDataset = mnistDataset()
# æ‰“å¼€ä¿å­˜è·¯å¾„ä¸‹çš„ckpt.txtæ–‡ä»¶ï¼Œä»¥å†™å…¥æ¨¡å¼
with open(os.path.join(savepath, 'ckpt.txt'), 'w') as f:
    # å°†ckptPathå†™å…¥æ–‡ä»¶
    f.writelines(ckptPath)

bs = 1
testLoader = DataLoader(dataset=testDataset, batch_size=bs, shuffle=False, num_workers=0)

netParams = snn.params('network.yaml')
m = NetworkBasic(netParams).to("cuda")
m = torch.nn.DataParallel(m).to(device)
m.eval()

m, epoch0 = checkpoint_restore(m, ckptPath, name='ckptBest', device=device)
print("start from epoch %d" % epoch0)

Mse = torch.nn.MSELoss(reduction='mean')

loss_sum = 0
l = []
count = 0

lossTime = lossEcm = 0

for k, (eventLr_pos, eventLr_neg, eventHr, path) in enumerate(testLoader):
    with torch.no_grad():
        eventLr_pos = eventLr_pos.to("cuda")
        eventLr_neg = eventLr_neg.to("cuda")
        eventHr = eventHr.to("cuda")

        output_pos = m(eventLr_pos)
        output_neg = m(eventLr_neg)
        output = output_pos + output_neg 

        eventList = getEventFromTensor(output)
        e = eventList[0]
        e = e[:, [0, 2, 1, 3]]
        # æœ€åä¿å­˜ä¸º .npy æ–‡ä»¶ï¼Œè¾“å‡ºè·¯å¾„ä¸º savepath + ç±»åˆ«ç›®å½• + æ–‡ä»¶å
        new_path = os.path.join(savepath, path[0])
        np.save(new_path, e.astype(np.int32))

        if k % 100 ==0:
            print("%d/%d"%(k, len(testLoader)))
