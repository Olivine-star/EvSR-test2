import sys
sys.path.append('..')
from model import NetworkBasic
from torch.utils.data import DataLoader, Dataset
import numpy as np
import slayerSNN as snn
import torch
from utils.ckpt import checkpoint_restore
from slayerSNN.spikeFileIO import event
import os
from utils.utils import getEventFromTensor

os.environ["CUDA_VISIBLE_DEVICES"] = "0"




def readNpSpikes(filename, timeUnit=1e-3):
    npEvent = np.load(filename)
    return event(npEvent[:, 1], npEvent[:, 2], npEvent[:, 3], npEvent[:, 0] * timeUnit * 1e3)


# -------------------------------
# âœ… è·¯å¾„è¯»å–å‡½æ•°ï¼ˆå†…è”ï¼‰=
# -------------------------------
def load_path_config(path_config='../nfs_path.txt'):
    path_dict = {}
    with open(path_config, 'r') as f:
        for line in f:
            if '=' in line:
                key, val = line.strip().split('=', 1)
                path_dict[key.strip()] = val.strip()
    return path_dict

# -------------------------------
# âœ… åŠ è½½è·¯å¾„é…ç½®
# -------------------------------
paths = load_path_config()
savepath = paths.get('savepath', '')
ckptPath = paths.get('ckptPath', '')




# ================================
# nfsDatasetï¼šå»æ‰ classList ç‰ˆæœ¬
# ================================
class nfsDataset(Dataset):
    def __init__(self):
        self.lrList, self.hrList, self.path = [], [], []

        # è¯»å–è·¯å¾„
        self.hrPath = paths.get('test_hr', '')
        self.lrPath = paths.get('test_lr', '')
        os.makedirs(savepath, exist_ok=True)          # åªå»ºä¸€æ¬¡è¾“å‡ºç›®å½•
        
        # åŸºæœ¬å½¢çŠ¶
        self.H, self.W, self.nTimeBins = 128, 128, 1500

        # â‘  åˆ—å‡ºå¹¶æ’åºå…¨éƒ¨ HR/LR æ–‡ä»¶ï¼ˆå‡è®¾éƒ½æ˜¯ .npyï¼‰
        hr_files = sorted([f for f in os.listdir(self.hrPath) if f.endswith('.npy')])
        lr_files = sorted([f for f in os.listdir(self.lrPath) if f.endswith('.npy')])

        # â‘¡ ç¡®ä¿æ–‡ä»¶åä¸€ä¸€å¯¹åº”
        assert hr_files == lr_files, "âš ï¸ HR å’Œ LR æ–‡ä»¶åä¸ä¸€è‡´ï¼Œè¯·æ£€æŸ¥ï¼"

        # â‘¢ æ„å»ºæ–‡ä»¶åˆ—è¡¨
        for fname in hr_files:
            self.hrList.append(os.path.join(self.hrPath, fname))
            self.lrList.append(os.path.join(self.lrPath, fname))
            self.path.append(fname)                   # ä»…æ–‡ä»¶åï¼Œç”¨äºä¿å­˜ç»“æœ

        print(f"ğŸ”¹ è¯»å– {len(self.hrList)} å¯¹ HR/LR æ ·æœ¬")

    def __getitem__(self, idx):
        # è¯»å–äº‹ä»¶ â†’ spike tensor
        eventHr = readNpSpikes(self.hrList[idx])
        eventLr = readNpSpikes(self.lrList[idx])

        eventLr1 = eventLr.toSpikeTensor(torch.zeros((2, self.H // 2, self.W // 2, self.nTimeBins)))
        eventHr1 = eventHr.toSpikeTensor(torch.zeros((2, self.H, self.W, self.nTimeBins)))

        assert eventHr1.sum() == len(eventHr.x)
        assert eventLr1.sum() == len(eventLr.x)

        return eventLr1, eventHr1, self.path[idx]     # path åªæ˜¯æ–‡ä»¶å

    def __len__(self):
        return len(self.lrList)



def main():
    device = 'cuda'
    testDataset = nfsDataset()

    with open(os.path.join(savepath, 'ckpt.txt'), 'w') as f:
        f.writelines(ckptPath)

    bs = 1
    testLoader = DataLoader(dataset=testDataset, batch_size=bs, shuffle=False, num_workers=1, drop_last=False)

    netParams = snn.params('network.yaml')
    m = NetworkBasic(netParams).to("cuda")
    m = torch.nn.DataParallel(m).to(device)
    m.eval()

    print(netParams['simulation'])

    m, epoch0 = checkpoint_restore(m, ckptPath, name="ckptBest")

    for k, (eventLr, eventHr, path) in enumerate(testLoader, 0):
        with torch.no_grad():
            eventLr = eventLr.to("cuda")
            eventHr = eventHr.to("cuda")

            output = m(eventLr)

            eventList = getEventFromTensor(output)
            e = eventList[0]
            e = e[:, [0,2,1,3]]
            new_path = os.path.join(savepath, path[0])  # path[0] ç°åœ¨å°±æ˜¯ 'xxx.npy'

            np.save(new_path, e.astype(np.int32))

        if k % 100 == 0:
            print(k, '/', len(testDataset))


if __name__ == '__main__':
    main()
